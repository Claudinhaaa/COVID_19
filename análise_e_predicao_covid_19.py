# -*- coding: utf-8 -*-
"""Análise_e_predicao_COVID-19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Or3To3s8BWZVtc3ABgIbDozH7iJp9HjJ

# **Análise Gráficos**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.ticker import PercentFormatter
import datetime
from google.colab import drive
import os

drive.mount('/content/drive')

data_directory = '/content/drive/Shareddrives/Mineração de Dados - COVID/banco_de_dados_bruto'

df = pd.read_csv(os.path.join(data_directory, 'COVID-19 em Dados.csv'), sep=',')
df_apple_mobility = pd.read_csv(os.path.join(data_directory, 'applemobilitytrends.csv'), sep=',')
df_google_mobility = pd.read_csv(os.path.join(data_directory, 'google_Global_Mobility_Report.csv'), sep=',')
df_vaccination_original = pd.read_csv(os.path.join(data_directory, 'vacinacao.csv'), sep=';')

# Removing rows with blank reference date
df = df[df['dt_referencia'].notnull()]

# Removing unnecessary column
if 'dt_atualizacao' in df:
  del df['dt_atualizacao']

# Converting dt_referencia column to date type
df['dt_referencia'] = pd.to_datetime(df['dt_referencia'], errors='coerce')

# Calculating daily values
# the fill_value parameter gets zero on invalid values
df['confirmados_day'] = df['confirmados'] - df['confirmados'].shift(fill_value=0)
df['obitos_day'] = df['obitos'] - df['obitos'].shift(fill_value=0)
df['recuperados_day'] = df['recuperados'] - df['recuperados'].shift(fill_value=0)

df.head(5)

df_apple = df_apple_mobility

df_apple = df_apple[df_apple['region'] == 'Pernambuco']

df['driving'] = df['dt_referencia'].apply(
  lambda x: df_apple[df_apple['transportation_type'] == 'driving'][str(x)[:10]]
)

df['walking'] = df['dt_referencia'].apply(
  lambda x: df_apple[df_apple['transportation_type'] == 'walking'][str(x)[:10]]
)

df.head(5)

df.describe()

df.corr()

df_rows = len(df.index)
print(f'Number of days: {df_rows}')

confirmed = int(df.iloc[-1]['confirmados'])
print(f'Total confirmed cases: {confirmed}')

deaths = int(df.iloc[-1]['obitos'])
print(f'Total deaths: {deaths}')

df_graph = pd.DataFrame({
    'date': df['dt_referencia'],
    'confirmed': df['confirmados'],
    'confirmed_day': df['confirmados_day'],
    'deaths': df['obitos'],
    'deaths_day': df['obitos_day']
})

display(df_graph.head(5))

df_graph = pd.melt(
    df_graph,
    id_vars=['date'],
    value_vars=list(df_graph.columns)[1:]
)

fig, ax = plt.subplots(figsize=(18, 6))

fig.get_axes()[0].set_yscale('log')

sns.lineplot(x='date', y='value', hue='variable', data=df_graph, ax=ax)

df_graph = pd.DataFrame({
    'date': df['dt_referencia'],
    #'deaths': df['tx_obitos'],
    'tx_oc_enfermaria': df['tc_oc_enf'],
    'tx_oc_uti': df['tx_oc_uti'],
})

df_graph = pd.melt(
    df_graph,
    id_vars=['date'],
    value_vars=list(df_graph.columns)[1:]
)

fig, ax = plt.subplots(figsize=(18, 6))

# fig.get_axes()[0].set_yscale('log')

sns.lineplot(x='date', y='value', hue='variable', data=df_graph, ax=ax)

fig, ax = plt.subplots(figsize=(15, 15))
sns.heatmap(df.corr(), annot=True, cmap='YlGnBu', linewidths=0.5, ax=ax)
plt.title('Data Set Correlation')

field = 'obitos'
value = df.iloc[0][field]
print(value)

df_graph = pd.DataFrame({
    'date': df['dt_referencia'],
    # 'deaths': df['obitos_day'],
    # field: value * df[field] / 100,
    # 'confirmados': value * df['confirmados_day'] / 100,
    'driving': df['driving'],
    'walking': df['walking'],
    # 'd+w': df['confirmados_day'] * ((df['driving'] + df['walking']) / 2) / 100,
})

df_graph = pd.melt(
    df_graph,
    id_vars=['date'],
    value_vars=list(df_graph.columns)[1:]
)

fig, ax = plt.subplots(figsize=(18, 6))
# fig.get_axes()[0].set_yscale('log')

sns.lineplot(x='date', y='value', hue='variable', data=df_graph, ax=ax)



fig, ax = plt.subplots(figsize=(18, 6))
sns.boxplot (x='tx_oc_uti',y='driving',data=df, ax=ax)

fig, ax = plt.subplots(figsize=(18, 6))
sns.boxplot (x='tc_oc_enf',y='walking',data=df, ax=ax)

fig, ax = plt.subplots(figsize=(20, 10))
sns.boxplot (x='obitos_day',y='driving',data=df, ax=ax)

fig, ax = plt.subplots(figsize=(18, 8))
sns.boxplot (x='obitos_day',y='tx_isolamento',data=df, ax=ax)

df_filter = df[df['confirmados_day'] < 4000]
df_filter_filter = df_filter[df_filter['confirmados_day'] > 0]

fig, ax = plt.subplots(figsize=(18, 8))
sns.stripplot (x='tx_oc_uti',y='confirmados_day',data=df_filter_filter)

#BarPlot code from first info of last year until the last day of the last month
data_barplot = pd.DataFrame({
    'day': df['dt_referencia'],
    'confirmed': df['confirmados_day'],
    'deaths': df['obitos_day']
})
today = datetime.date.today()
frist_day = today.replace(day=1)
lastMonth = frist_day - datetime.timedelta(days=1)

data_barplot['day'] = pd.to_datetime(data_barplot['day'],  format="%Y-%d-%m")
data_barplot['day'] = data_barplot[(data_barplot['day'].dt.date <= lastMonth)]
data_barplot.groupby(pd.Grouper(key='day', freq="1M")).sum()
table = data_barplot.groupby(pd.Grouper(key='day', freq="M")).sum()
table.set_index(table.index.month_name().rename('Mês').map(lambda tt: tt[:3]), inplace=True)
table.plot.bar()

#BoxPlot code from first info of last year until the last day of the last month
data_boxplot = pd.DataFrame({
    'day': df['dt_referencia'],
    'deaths': df['obitos_day'],
    'uti_cases': df['uti'],
    'recovered': df['recuperados_day'],
    'confirmed': df['confirmados_day']
})
today = datetime.date.today()
frist_day = today.replace(day=1)
lastMonth = frist_day - datetime.timedelta(days=1)

data_boxplot['day'] = pd.to_datetime(data_boxplot['day'], format="%Y-%d-%m")
data_boxplot['day'] = data_boxplot[(data_boxplot['day'].dt.date <= lastMonth)]
table = data_boxplot.groupby(pd.Grouper(key='day', freq="M")).sum()
table.set_index(table.index.month_name().rename('Mês').map(lambda tt: tt[:3]), inplace=True)
display(table)
table.plot.box()

data_scattetplot = pd.DataFrame({
    'day': df['dt_referencia'],
    'confirmed': df['confirmados_day']
})
today = datetime.date.today()
frist_day = today.replace(day=1)
lastMonth = frist_day - datetime.timedelta(days=1)

# data_scattetplot['day'] = pd.to_datetime(data_scattetplot['day'], format="%Y-%d-%m")
data_scattetplot['day'] = data_scattetplot[(data_scattetplot['day'].dt.date <= lastMonth)]
# table = data_scattetplot.groupby(pd.Grouper(key='day', freq="M")).sum()
#table.set_index(table.index.month_name().rename('Mês').map(lambda tt: tt[:3]), inplace=True)
# display(table)
#table.plot.scatter(x='dt_referencia',y='confirmados_day')
# table.reset_index().plot(kind='scatter', x='index', y='confirmados_day')

df_graph = df
df_graph = df_graph.dropna()
# df_graph = df_graph.reset_index(drop=True)
df_graph = df_graph[df_graph['confirmados_day'] < 4000]
df_graph = df_graph[df_graph['confirmados_day'] > 0]

df_graph = pd.DataFrame({
    'Date': df_graph['dt_referencia'],
    # 'Mobility': ((df_graph['driving'] + df_graph['walking']) / 2) * reference,
    # 'Driving': df_graph['driving'],
    'Walking': df_graph['walking'],
    'Occupancy rate of wards': df_graph['tx_oc_uti'] * 100,
    'ICU occupancy rate': df_graph['tc_oc_enf'] * 100
})

# display(df_graph)
# display(list(df_graph.columns)[1:])

df_graph = pd.melt(
    df_graph,
    id_vars=['Date'],
    value_vars=list(df_graph.columns)[1:]
)

fig, ax = plt.subplots(figsize=(18, 6))
fig.get_axes()[0].set_yscale('log')

sns.lineplot(x='Date', y='value', hue='variable', data=df_graph, ax=ax)

# display(df)

# Removing rows with blank columns
new_df = df.dropna(subset=['dt_referencia', 'tx_oc_uti'])

new_df = pd.DataFrame({
    'date': new_df['dt_referencia'],
    'confirmed': new_df['confirmados'],
    'deaths': new_df['obitos'],
    'death_rate': new_df['tx_obitos'],
    'recovered': new_df['recuperados'],
    'original_icu_rate': new_df['tx_uti'],
    'icu_occupancy_rate': new_df['tx_oc_uti'],
    'new_tests': new_df['testes_novos'],
    'icu': new_df['uti'],
    # 'deaths_ma': new_df['obitos'].rolling(window=7).mean(),
    # 'death_by_day': new_df['obitos'] - new_df['obitos'].shift(fill_value=0),
    # 'icu_rate': new_df['uti'] / (new_df['confirmados'] - new_df['confirmados'].shift(fill_value=0)),
})

new_df['confirmed_by_day'] = new_df['confirmed'] - new_df['confirmed'].shift(fill_value=0)
new_df['confirmed_ma'] = new_df['confirmed_by_day'].rolling(window=7).mean()
new_df['death_by_day'] = new_df['deaths'] - new_df['deaths'].shift(fill_value=0)
new_df['deaths_ma'] = new_df['death_by_day'].rolling(window=7).mean()
new_df['icu_rate'] = new_df['icu'] / new_df['confirmed_by_day']

# Removing unnecessary column
del new_df['icu']

# Apple Mobility
# Available data: walking, driving

df_mobility = df_apple_mobility[df_apple_mobility['region'] == 'Pernambuco']
new_df['apple_mobility_index'] = new_df['date'].apply(
  lambda x: df_mobility[df_mobility['transportation_type'] == 'walking'][str(x)[:10]]
)

# display(df_mobility.head(5))

# Google Mobility
# Available data: retail_and_recreation, grocery_and_pharmacy, parks, transit_stations, workplaces, residential

df_mobility = df_google_mobility[df_google_mobility['sub_region_1'] == 'State of Pernambuco']

# display(df_mobility[df_mobility.date == '2020-04-16']['sub_region_2'])
# display(len(df_mobility[df_mobility.date == '2020-04-16'].index))
# display(len(df_google_mobility.index))

new_df['google_mobility_index'] = new_df['date'].apply(
  # lambda x: df_mobility[df_mobility['date'] == str(x)[:10]]['retail_and_recreation_percent_change_from_baseline'].mean()
  lambda x: df_mobility[df_mobility['date'] == str(x)[:10]][[
    'retail_and_recreation_percent_change_from_baseline', 
    'grocery_and_pharmacy_percent_change_from_baseline', 
    'parks_percent_change_from_baseline', 
    'transit_stations_percent_change_from_baseline',
    'workplaces_percent_change_from_baseline',
    'residential_percent_change_from_baseline'
  ]].apply(np.mean).mean() + 100
)

# new_df['mobility_ma'] = ((new_df['apple_mobility_index'] + new_df['google_mobility_index']) / 2).rolling(window=7).mean()

# display(df_mobility.head(5))

display(new_df)

df_graph = new_df

df_graph = df_graph.dropna()

df_graph = pd.DataFrame({
    'Date': df_graph['date'],
    'Apple Mobility': df_graph['apple_mobility_index'],
    'Google Mobility': df_graph['google_mobility_index'],
    # 'Moving average of mobility': ((df_graph['apple_mobility_index'] + df_graph['google_mobility_index']) / 2).rolling(window=7).mean(),
})

df_graph = pd.melt(
    df_graph,
    id_vars=['Date'],
    value_vars=list(df_graph.columns)[1:]
)

fig, ax = plt.subplots(figsize=(18, 6))
# fig.get_axes()[0].set_yscale('log')

sns.lineplot(x='Date', y='value', hue='variable', data=df_graph, ax=ax)

fig, ax = plt.subplots(figsize=(15, 15))
sns.heatmap(new_df.corr(), annot=True, cmap='YlGnBu', linewidths=0.5, ax=ax)
plt.title('Data Set Correlation')

# display(list(df_vaccination_original.columns))
# display(df_vaccination_original.head(10))

df_vaccination = df_vaccination_original

df_vaccination = pd.DataFrame({
    'date': df_vaccination['vacina_dataaplicacao'],
    'persons_category': df_vaccination['vacina_categoria_nome'],
    'persons_age': df_vaccination['paciente_idade'],
    'persons_biological_sex': df_vaccination['paciente_enumsexobiologico'],
    'persons_race': df_vaccination['paciente_racacor_valor'],
    'persons_race': df_vaccination['paciente_racacor_valor'],
    'vaccine_manufacturer': df_vaccination['vacina_fabricante_nome'],
    'vaccine_dose': df_vaccination['vacina_descricao_dose'].str.strip(),
    # 'fully_vaccinated_person': (df_vaccination['vacina_descricao_dose'] == '2ª Dose' or df_vaccination['vacina_descricao_dose'] == 'Dose')
})

# display(df_vaccination.head(5))

df_test = df_vaccination
df_test['value'] = 1
df_test = df_test.groupby(['date', 'vaccine_dose'], as_index=False)['value'].count()
# display(df_test)
# df_test = df_test.pivot(index='date', columns='vaccine_dose')
# df_test['1ª Dose'] = df_test['1ª Dose'] + df_test['1ª Dose'].shift(fill_value=0)
# df_test['2ª Dose'] = df_test['2ª Dose'] + df_test['2ª Dose'].shift(fill_value=0)
# df_test['Dose'] = df_test['Dose'] + df_test['Dose'].shift(fill_value=0)
display(df_test)
display(list(df_test.columns))

df_vaccination_1 = df_test[df_test['vaccine_dose'].str.contains('1')]['date']
df_vaccination_2 = df_test[df_test['vaccine_dose'].str.contains('2')]['date']
df_vaccination_3 = df_test[df_test['vaccine_dose'] == 'Dose']['date']
display(df_vaccination_1)
display(df_vaccination_2)
display(df_vaccination_3)

# display(df_vaccination[df_vaccination['vaccine_dose'].str.contains('Dose')])
# display(df_vaccination[df_vaccination['vaccine_dose'] == 'Dose'])

# df_vaccination_by_dose = df_vaccination.groupby('date')
# df_vaccination_by_dose = df_vaccination.groupby(['date','vaccine_dose']).sum().groupby(level=0).cumsum().reset_index()
# display(df_vaccination.groupby(['date','vaccine_dose'])['vaccine_dose'].count())
# df_vaccination_by_dose = df_vaccination.groupby('date')
# df_vaccination_by_dose['1a dose'] = df_vaccination_by_dose['date'].apply(
#     # lambda x: df_vaccination_by_dose[(df_vaccination_by_dose['date'] == str(x)[:10]) & (df_vaccination_by_dose['vaccine_dose'] == 'Dose')]
#     lambda x: 1
# )
# display(df_vaccination.groupby(['date', 'vaccine_dose'])['date'].count())
# df_vaccination_dates = df_vaccination.drop_duplicates()['date']

# display(df_vaccination_dates)

# df_vaccination_by_doses = pd.DataFrame({
#     'date': df_vaccination_dates,
# })

# df_vaccination_by_doses['1a'] = df_vaccination_by_doses['date'].apply(
#   lambda x: df_vaccination[(df_vaccination['date'] == str(x)[:10]) & (df_vaccination['vaccine_dose'] == 'Dose')]['date'].count()
# )

# display(df_vaccination_by_doses)

# df_vaccination

# df_vaccination[df_vaccination['vaccine_manufacturer'].str.contains('Janssen')]

"""# **Pré-Processamento**

Realizado no Pentaho

# **Classificador (Base Geral)**
"""

from google.colab import drive

drive.mount('/content/drive')

data_directory = '/content/drive/Shareddrives/Mineração de Dados - COVID/banco_de_dados_bruto/'
data = data_directory + 'basegeral.csv'

df = pd.read_csv(data)

import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

df = pd.read_csv(os.path.join(data_directory, 'basegeral.csv'), sep=';')
df = df[df['dt_notificacao'].notnull()]
df = df[df['Resultado'].notnull()]
df = df[df['Sexo'].notnull()]
df = df[~df['Resultado'].str.contains("AGUARDANDO")]
df = df[~df['Resultado'].str.contains("DETECTAVEL")]
df = df[df['sintomas'].notnull()]
df = df[df['comorbidades'].notnull()]

df['dt_notificacao'] = pd.to_datetime(df['dt_notificacao'], errors='coerce')
dataf = pd.DataFrame({
    'data':df['dt_notificacao'],
    'sexo':df['Sexo'],
    'sintomas':df['sintomas'],
    'comorbidade':df['comorbidades'],
    'faixa_etaria':df['faixa_etaria'],
    'resultado':df['Resultado']
})

#Tratamento Sintomas
dataf['sintomas'] = dataf.sintomas.str.replace('DOR DE CABECA', 'DORCABECA')
dataf['sintomas'] = dataf.sintomas.str.replace('DESCONFORTO RESPIRATORIO', 'DIFRESP')
dataf['sintomas'] = dataf.sintomas.str.replace('APERTO TORACICO', 'APERTORX')
dataf['sintomas'] = dataf.sintomas.str.replace('SATURACAO O2 < 95', 'SATURACAO')
dataf['sintomas'] = dataf.sintomas.str.replace('ALTERACAOPERDA DE OLFATO EOU PALADAR', 'OLFATO/PALADAR')
dataf['sintomas'] = dataf.sintomas.str.replace('ERUPCOES CUTANEAS', 'ERUPCUT')
dataf['sintomas'] = dataf.sintomas.str.replace('CONGESTAO NASAL', 'CONGESTNASAL')
dataf['sintomas'] = dataf.sintomas.str.replace('DOR DE GARGANTA', 'DORGARGANTA')
dataf['sintomas'] = dataf.sintomas.str.replace('TIRAGEM INTERCOSTAL', 'TIRAGEM')
dataf['sintomas'] = dataf.sintomas.str.replace('ASA DE NARIZ', 'ASANARIZ')
#FEBRE, TOSSE, DISPNEIA, CORIZA, VOMITO, CANSACOFADIGA, MIALGIA, BATIMENTO, DIARREIA

dataf['sintomas'] = dataf.sintomas.str.replace('  ', '-')
dataf['sintomas'] = dataf.sintomas.str.replace(' ', '-')

#Tratamento Comorbidade
dataf['comorbidade'] = dataf.comorbidade.str.replace('DOENCA HEPATICA CRONICA', 'HEPATITE')
dataf['comorbidade'] = dataf.comorbidade.str.replace('DOENCAS RENAIS CRONICAS', 'RINS')
dataf['comorbidade'] = dataf.comorbidade.str.replace('DOENCAS CARDIACAS OU VASCULARES', 'CARDIOVASC')
dataf['comorbidade'] = dataf.comorbidade.str.replace('DOENCAS RESPIRATORIAS CRONICAS DESCOMPENSADAS', 'ASMA/OUTROS')
dataf['comorbidade'] = dataf.comorbidade.str.replace('DOENCAS RESPIRATORIAS CRONICAS', 'ASMA/OUTROS')
dataf['comorbidade'] = dataf.comorbidade.str.replace('PORTADOR DE DOENCAS CROMOSSOMICAS OU ESTADO DE FRAGILIDADE IMUNOLOGICA', 'IMUNODEFICIENCIA')
#DIABETES, GRAVIDEZ, SOBREPESOOBESIDADE, IMUNOSSUPRESSAO

dataf['comorbidade'] = dataf.comorbidade.str.replace('  ', '-')
dataf['comorbidade'] = dataf.comorbidade.str.replace(' ', '-')

#Tratamento Resultados
dataf.loc[dataf.resultado.str.contains("NEGATIVO"), "resultado"] = 'NEGATIVO'
dataf.loc[dataf.resultado.str.contains("NAO"), "resultado"] = 'NEGATIVO'
dataf.loc[dataf.resultado.str.contains("POSITIVO"), "resultado"] = 'POSITIVO'
dataf.loc[dataf.resultado.str.contains("REAGENTE"), "resultado"] = 'POSITIVO'

today = datetime.date.today().replace(day=1)
threeMonths = today - datetime.timedelta(days=92)
dataf['data'] = dataf[(dataf['data'].dt.date > threeMonths)]
dataf = dataf.dropna()
dataf['data'] = pd.to_datetime(dataf['data']).dt.date
classfication_frame = pd.DataFrame({
    'sintomas':dataf['sintomas'],
    'comorbidade':dataf['comorbidade'],
    'sexo':dataf['sexo'],
    'faixa_etaria':dataf['faixa_etaria'],
    'resultado':dataf['resultado']
})

classfication_frame.reset_index(drop=True, inplace=True)

classfication_frame.to_csv(data_directory+'arquivoClassificacao.csv')

num_positivos = classfication_frame.loc[classfication_frame['resultado'] == 'POSITIVO'].count()[0]
num_negativos = classfication_frame.loc[classfication_frame['resultado'] == 'NEGATIVO'].count()[0]
print(num_positivos)
print(num_negativos)

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(classfication_frame['sintomas'].values)
X = X.toarray()

y = classfication_frame['resultado'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2, random_state=11)

clf = MultinomialNB()
clf.fit(X_train, y_train)

print(clf.score(X_train, y_train))
print(clf.score(X_test, y_test))


##### Model evaluation

predictions = clf.predict(X_test)

cm = confusion_matrix(y_test, predictions)

plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=['POSITIVO', 'NEGATIVO'], yticklabels=['NEGATIVO', 'POSITIVO'], cmap=plt.cm.Blues, cbar=False)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()
symptoms='DORGARGANTA-DORCABECA'
vectorized_symptoms = vectorizer.transform([symptoms]).toarray()
clf.predict(vectorized_symptoms)

"""# **Classificação(Base Tratada)**"""

import seaborn as sns
from sklearn.tree import DecisionTreeClassifier 
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

pentaho_database_path = '/content/drive/Shareddrives/Mineração de Dados - COVID/BD_pentaho_pre_processamento'

df = pd.read_csv(os.path.join(pentaho_database_path, 'bd_covid.csv'), sep=';')
data_confirmados = pd.DataFrame({
    'data':df['dt_referencia'],
    'confirmados_dia':df['confirmados_dia']
})

data_obitos = pd.DataFrame({
    'data':df['dt_referencia'],
    'obitos_dia':df['obitos_dia']
})

data_recuperados = pd.DataFrame({
    'data':df['dt_referencia'],
    'recuperados_dia':df['recuperados_dia']
})





#Classificação 
#0 = Baixo, 1= Médio, 2= Alto
data_confirmados['cresc_confirmados'] = pd.cut(data_confirmados['confirmados_dia'], [0,350,750,2000], labels=[0,1,2])
data_obitos['cresc_obitos'] = pd.cut(data_obitos['obitos_dia'], [0,30,60,200], labels=[0,1,2])
data_recuperados['cresc_recuperados'] = pd.cut(data_recuperados['recuperados_dia'], [0,350,750,2000], labels=[0,1,2])

data_confirmados['cresc_confirmados'] = data_confirmados['cresc_confirmados'].fillna(0)
data_obitos['cresc_obitos'] = data_obitos['cresc_obitos'].fillna(0)
data_confirmados.head()

num_baixo = data_obitos.loc[data_obitos['cresc_obitos'] == 0].count()[2]
num_medio = data_obitos.loc[data_obitos['cresc_obitos'] == 1].count()[2]
num_alto = data_obitos.loc[data_obitos['cresc_obitos'] == 2].count()[2]

display(data_obitos)

print(num_baixo)
print(num_medio)
print(num_alto)

X = data_obitos['obitos_dia'].values.reshape(-1,1)
y = data_obitos['cresc_obitos']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

gnb = GaussianNB()
gnb.fit(X_train, y_train)
print('Accuracy of GNB classifier on training set: {:.2f}'
     .format(gnb.score(X_train, y_train)))
print('Accuracy of GNB classifier on test set: {:.2f}'
     .format(gnb.score(X_test, y_test)))

prediction_array = np.array([18,500,1242,75,24,100])

clf = MultinomialNB()
clf.fit(X_train, y_train).predict(prediction_array.reshape(-1,1))
#gnb.fit(X_train, y_train).predict(prediction_array.reshape(-1,1))

"""# **Agrupamento**"""

#Correlacao

from google.colab import drive
import pandas as pd
import os 
import seaborn as sns

drive.mount('/content/drive')

#data_directory = '/content/drive/Shareddrives/Mineração de Dados - COVID/banco_de_dados_bruto/'
#data = data_directory + '/basegeral.csv'
pentaho_database_path = '/content/drive/Shareddrives/Mineração de Dados - COVID/BD_pentaho_pre_processamento'

df2 = pd.read_csv(os.path.join(pentaho_database_path, 'bd_covid.csv'), sep=';')
#df2 = pd.read_csv(data, sep= ';')

#df2['confirmados_dia'].describe()

df_2 = pd.DataFrame({
    'confirmados' : df2['confirmados_dia'],
    'obitos' : df2['obitos_dia'],
    #'transito' : df['transito_google']
})

y1=df_2.values[:,1]
x1=df_2.values[:,0]

#y1.max()

df2.corr()

corr = df2.corr()
ax = sns.heatmap(
    corr, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=90,
    horizontalalignment='right'
);

#Verificar residencia x trabalho (google)
#Confirmar as relações óbvias e remover (se necessário)

#Agrupamento
from sklearn.cluster import KMeans 

import numpy as np 
from matplotlib import pyplot as plt 


kmeans_2 = KMeans(n_clusters=3, init='random', max_iter=300) # init = k means é um algoritmo de iteracao mais assertiva
pred_2=kmeans_2.fit_predict(df_2)


plt.scatter(x1,y1,c = kmeans_2.labels_) #posicionamento dos eixos x e y
plt.xlim(0, 10188) #range do eixo x
plt.ylim(0, 140) #range do eixo y
plt.grid() #função que desenha a grade no nosso gráfico
plt.scatter(kmeans_2.cluster_centers_[:,0],kmeans_2.cluster_centers_[:,1],s=100 , c = 'red') #posição de cada centroide no gráfico
plt.show()

df = pd.read_csv(os.path.join(pentaho_database_path, 'bd_covid.csv'), sep=';')
#df = pd.read_csv(data, sep= ';')
#df['confirmados_dia'].describe()

df_1 = pd.DataFrame({
   # 'confirmados' : df['confirmados'],
   # 'obitos' : df['obitos'],
  #  'tx_obitos' : df['tx_obitos'],
  #  'recuperados' : df['recuperados'],
  #  'tx_recuperados' : df['tx_recuperados'],
  #  'tx_uti' : df['tx_uti'],
    'testes_novos' : df['testes_novos'],
    'tx_oc_uti' : df['tx_oc_uti'],
    'confirmados_dia' : df['confirmados_dia'],
    'obitos_dia' : df['obitos_dia'],
    'recuperados_dia' : df['recuperados_dia'],
    '1_dose_dia' : df['1_dose_dia'],
    '2_dose_dia' : df['2_dose_dia'],
    'dose_unica_dia' : df['dose_unica_dia'],
  #  'decreto' : df['decreto'],
    'transito_google' : df['transito_google'],
  #  'trabalho_google' : df['trabalho_google'],
  #  'residencia_google' : df['residencia_google'],
   # 'driving_apple' : df['driving_apple'],
  #  'walking_apple' : df['walking_apple'],
   # '1_dose_total' : df['1_dose_total'],
   # '2_dose_total' : df['2_dose_total'],
  #  'dose_unica_total' : df['dose_unica_total']
})
x_=2
y_=3

y=df_1.values[:,y_]
x=df_1.values[:,x_]

y.max()

#metodo do cotovelo
wcss = []
 
for i in range(1, 20):
    kmeans = KMeans(n_clusters = i, init = 'random')
    kmeans.fit(df_1)
    print (i,kmeans.inertia_)
    wcss.append(kmeans.inertia_)  
plt.plot(range(1, 20), wcss)
plt.title('O Metodo Elbow - Cotovelo')
plt.xlabel('Numero de Clusters')
plt.ylabel('WSS') # soma dos quadrados intra-clusters
plt.show()

#Agrupamento
from sklearn.cluster import KMeans 

import numpy as np 
from matplotlib import pyplot as plt 


kmeans = KMeans(n_clusters=10, init='random',  max_iter=300) # init = k means é um algoritmo de iteracao mais assertiva
pred=kmeans.fit_predict(df_1)


plt.scatter(x,y,c = kmeans.labels_) #posicionamento dos eixos x e y
plt.xlim(0, 10188) #range do eixo x
plt.ylim(0, 140) #range do eixo y
plt.grid() #função que desenha a grade no nosso gráfico
plt.scatter(kmeans.cluster_centers_[:,x_],kmeans.cluster_centers_[:,y_],s=100 , c = 'red') #posição de cada centroide no gráfico
plt.show()

y=kmeans.labels_
df.insert(1,"grupo", y, True)
kmeans.cluster_centers_

df['confirmados_dia'] = df['confirmados_dia'].abs()
df['obitos_dia'] = df['obitos_dia'].abs()
df

import plotly.express as px 

fig = px.bar(df, x="dt_referencia", y="obitos_dia", 
             color="grupo", hover_data = ['confirmados_dia'],
             barmode = 'group') 
   
fig.show()





"""# **Regressão**"""

from pandas import Series, DataFrame
from sklearn.model_selection import train_test_split

# display(df[['confirmados_dia','obitos_dia','trabalho_google','tx_oc_uti','2_dose_total','dose_unica_total']][:5])

x = df[['confirmados_dia','trabalho_google','tx_oc_uti','2_dose_total','dose_unica_total']]

y = df['obitos_dia']

# 70% dos dados para treino e 30% para teste.
x_train, x_test, y_train, y_test = train_test_split(x, df.obitos_dia, test_size=0.3)

# Tamanho dos dados de treino.
x_train.shape, y_train.shape

# Tamanho dos dados de teste.
x_test.shape, y_test.shape

from sklearn.linear_model import LinearRegression
lreg = LinearRegression()

#Treinando o modelo
lreg.fit(x_train,y_train)

pred = lreg.predict(x_test)

#Calculando o MSE (Mean Square Error)
mse = np.mean((pred - y_test)**2)

display(mse) 

#Calculando coeficientes
coeff = DataFrame(x_train.columns)
coeff['Coeficientes'] = Series(lreg.coef_)
coeff

#Calculando o r-squared
lreg.score(x_test,y_test)

predicoes = pd.DataFrame(pred[:149])
# predicoes = pred[:100]

# y_teste = pd.DataFrame(y_test.values[:149])
y_teste = y_test.values[:149]

# display(y_test)
# display(y_teste)

# df0 = y_test
display(y_teste)



plt.style.use("ggplot")
plt.figure(figsize=(12,8))
plt.xlabel('..')
plt.ylabel('Predição de Óbitos')
plt.title('Valores reais vs preditos')
plt.plot(y_test.index, predicoes)
plt.plot(y_test.index, y_test)
# plt.plot(df0.index, df0)
plt.legend(['Predições','Valores Reais'])
plt.show()

display(y_test.index)

# display(df['obitos'].values.reshape(-1, 1))
# display(df.head())

x = df[['confirmados_dia','trabalho_google','tx_oc_uti','2_dose_total','dose_unica_total']]
y = df['obitos_dia'].values.reshape(-1, 1)

display(x)
from sklearn.model_selection import train_test_split
xtreino, xteste, ytreino, yteste = train_test_split(x, y, test_size=0.3)

# xtreino.shape, xteste.shape, ytreino.shape, yteste.shape

from sklearn.linear_model import LinearRegression
modelolm = LinearRegression().fit(xtreino, ytreino)

previsoes = modelolm.predict(xteste)
previsoes[0:9]

modelolm.score(xteste, yteste)

modelolm.intercept_

modelolm.coef_

from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(yteste, previsoes)
mae